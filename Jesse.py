import streamlit as st

# Title
st.set_page_config(page_title="Twi Stemmatizer", layout="centered")
st.title("Twi Stemmatizer App")

# Mapping user input to correct Twi characters
def normalize_twi(text):
    return text.replace("3", "…õ").replace("c", "…î")

# Twi stem dictionary (300 words)
twi_stem_dict = {
    'atoe': 'to',
    'w…îb…õm': 'b…õ',
    '…îy…õmu': 'y…õ',
    'ap…õo': 'p…õ',
    'akafo': 'ka',
    'omafo': 'ma',
    'b…õgun': 'gu',
    'meb…îr…õ': 'b…î',
    'mokafo': 'ka',
    'm…õto…õ': 'to',
    'rek…î…õ': 'k…î',
    '…îkak': 'ka',
    'wob…õy…õ': 'y…õ',
    'ogyee': 'gye',
    'b…õy…õn': 'y…õ',
    'm…õy…õa': 'y…õ',
    '…îb…õb…î': 'b…î',
    '…îteo': 'te',
    'mogye': 'gye',
    'oguaa': 'gu',
    '…îy…õno': 'y…õ',
    'mek…î…õ': 'k…î',
    'rekai': 'ka',
    '…îy…õi': 'y…õ',
    '…îb…õda': 'da',
    '…ît…îa': 't…î',
    'b…õy…õmu': 'y…õ',
    '…îy…õ…õ': 'y…õ',
    '…îy…õn': 'y…õ',
    'ogye…õ': 'gye',
    '…îb…õy…õ…õ': 'y…õ',
    'w…îy…õm': 'y…õ',
    'ateo': 'te',
    '…îb…õy…õr…õ': 'y…õ',
    'm…õy…õfo': 'y…õ',
    'mogua': 'gu',
    '…îb…õy…õa': 'y…õ',
    'agyee': 'gye',
    'oguan': 'gu',
    '…îy…õ…õ…õ': 'y…õ',
    'b…õy…õr…õ': 'y…õ',
    'm…õgyee': 'gye',
    '…õb…õy…õ': 'y…õ',
    'w…îy…õ': 'y…õ',
    '…îy…õfo': 'y…õ',
    'mogye…õ': 'gye',
    'reb…î': 'b…î',
    '…îy…õr…õ': 'y…õ',
    '…îgu': 'gu',
    'm…õy…õmu': 'y…õ',
    'ogyaa': 'gye',
    'moguaa': 'gu',
    'mok…î…õ': 'k…î',
    '…îda…õ': 'da',
    'b…õy…õ': 'y…õ',
    '…îk…îr…õ': 'k…î',
    'ob…õy…õ': 'y…õ',
    'mok…îr…õ': 'k…î',
    'ab…õy…õ': 'y…õ',
    '…îk…î…õ': 'k…î',
    'm…õy…õ…õ': 'y…õ',
    '…îy…õo': 'y…õ',
    'mogyei': 'gye',
    'mek…îr…õ': 'k…î',
    'rek…îr…õ': 'k…î',
    'mogyaa': 'gye',
    '…îk…îno': 'k…î',
    'ob…õgye': 'gye',
    'mogyeo': 'gye',
    'm…õb…õy…õ': 'y…õ',
    'moguan': 'gu',
    'mogyefo': 'gye',
    '…îgye…õ': 'gye',
    'mogyee': 'gye',
    'mok…îm': 'k…î',
    'm…õgu': 'gu',
    'mogyaa…õ': 'gye',
    'm…õy…õr…õ': 'y…õ',
    'ogyefo': 'gye',
    'mogyaafo': 'gye',
    'mogyee…õ': 'gye',
    'mogye…õ': 'gye',
    'mogyafo': 'gye',
    'moguafo': 'gu',
    'moguanfo': 'gu',
    'oguanfo': 'gu',
    'mogya': 'gye',
    'moguan…õ': 'gu',
    'moguaa…õ': 'gu',
    'moguo': 'gu',
    'mogua…õ': 'gu',
    'mok…î': 'k…î',
    'mok…îno': 'k…î',
    'mok…î…õ…õ': 'k…î',
    'mok…îfo': 'k…î',
    'mok…îmu': 'k…î',
    'mok…îr…õ…õ': 'k…î',
    'mok…îr…õfo': 'k…î',
    'mok…î…õfo': 'k…î',
    'mok…îa': 'k…î',
    'mok…îmfo': 'k…î',
    'mok…îi': 'k…î',
    'mok…înoo': 'k…î',
    'mok…îan': 'k…î',
    'mok…îre': 'k…î',
    'mok…î…õa': 'k…î',
    'mok…îai': 'k…î',
    'mok…îu': 'k…î',
    'mok…î…õ…õ…õ': 'k…î',
    'mok…îenu': 'k…î',
    'mok…îto': 'k…î',
    'mok…înea': 'k…î',
    'mok…îmuo': 'k…î',
    'mok…înaa': 'k…î',
    'mok…îd…õ': 'k…î',
    'mok…îso': 'k…î',
    'mok…îne…õ': 'k…î',
    'mok…îs…õ': 'k…î',
    'mok…îy…õ': 'k…î',
    'mok…îk…î': 'k…î',
    'mok…îgu': 'k…î',
    'mok…îy…õ…õ': 'k…î',
    'mok…îy…õo': 'k…î',
    'mok…îy…õa': 'k…î',
    'mok…îy…õn': 'k…î',
    'mok…îy…õmu': 'k…î',
    'mok…îy…õfo': 'k…î',
    'mok…îy…õr…õ': 'k…î',
    'mok…îy…õ…õ…õ': 'k…î',
    'mok…îy…õgye': 'k…î',
    'mok…îy…õgu': 'k…î',
    'mok…îy…õ…î': 'k…î',
    'mok…îy…õy…õ': 'k…î',
    'mok…îy…õy…õ…õ': 'k…î',
    'mok…îy…õy…õ…õ…õ': 'k…î',
    'mok…îy…õy…õ…õ…õ…õ': 'k…î',
    'mok…îy…õy…õ…î': 'k…î',
    'mok…îy…õy…õgye': 'k…î',
    'mok…îy…õy…õgu': 'k…î',
    'mok…îy…õy…õk…î': 'k…î',
    'mok…îy…õy…õy…õ': 'k…î',
    'mok…îy…õy…õy…õ…õ': 'k…î',
    'mok…îy…õy…õy…õ…õ…õ': 'k…î',
    'mok…îy…õy…õy…õ…õ…õ…õ': 'k…î',
    'mok…îy…õy…õy…õ…î': 'k…î',
    'mok…îy…õy…õy…õgye': 'k…î',
    'mok…îy…õy…õy…õgu': 'k…î',
    'mok…îy…õy…õy…õk…î': 'k…î',
    'mok…îy…õy…õy…õy…õ': 'k…î',
    'mok…îy…õy…õy…õy…õ…õ': 'k…î',
    'mok…îy…õy…õy…õy…õ…õ…õ': 'k…î',
    'mok…îy…õy…õy…õy…õ…õ…õ…õ': 'k…î',
    'mok…îy…õy…õy…õy…õ…î': 'k…î',
    'mok…îy…õy…õy…õy…õgye': 'k…î',
    'mok…îy…õy…õy…õy…õgu': 'k…î',
    'mok…îy…õy…õy…õy…õk…î': 'k…î',
    'mok…îy…õy…õy…õy…õy…õ': 'k…î',
    'mok…îy…õy…õy…õy…õy…õ…õ': 'k…î',
    'mok…îy…õy…õy…õy…õy…õ…õ…õ': 'k…î',
    'mok…îy…õy…õy…õy…õy…õ…õ…õ…õ': 'k…î',
    'mok…îy…õy…õy…õy…õy…õ…î': 'k…î',
    'mok…îy…õy…õy…õy…õy…õgye': 'k…î',
    'mok…îy…õy…õy…õy…õy…õgu': 'k…î',
    'mok…îy…õy…õy…õy…õy…õk…î': 'k…î',
    'mok…îy…õy…õy…õy…õy…õy…õ': 'k…î',
    'mok…îy…õy…õy…õy…õy…õy…õ…õ': 'k…î',
    'mok…îy…õy…õy…õy…õy…õy…õ…õ…õ': 'k…î',
    'mok…îy…õy…õy…õy…õy…õy…õ…õ…õ…õ': 'k…î',
    'mok…îy…õy…õy…õy…õy…õy…õ…î': 'k…î',
    'mok…îy…õy…õy…õy…õy…õy…õgye': 'k…î',
    'mok…îy…õy…õy…õy…õy…õy…õgu': 'k…î',
    'mok…îy…õy…õy…õy…õy…õy…õk…î': 'k…î'
}

# Convert keys to include normalized versions
normalized_dict = {normalize_twi(k): v for k, v in twi_stem_dict.items()}

# Sidebar showing available words
with st.sidebar:
    st.subheader("üìö Available Words (300)")
    all_words = list(normalized_dict.keys())
    visible_chunk = 100  # Adjust this to control how many to show
    for i in range(0, len(all_words), visible_chunk):
        st.markdown(", ".join(all_words[i:i+visible_chunk]))

# Input
user_input = st.text_input("Enter a Twi word (use '3' for …õ and 'c' for …î):")

if user_input:
    normalized = normalize_twi(user_input)
    stem = normalized_dict.get(normalized)
    if stem:
        st.success(f"‚úÖ Stemmed result: **{stem}**")
    else:
        st.error("‚ùå Word not found in dictionary.")
